<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- <script src="https://cdn.tailwindcss.com/3.3.1"></script> -->

  <!-- axiosの読み込み -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/axios/1.3.4/axios.min.js"></script>
  <title>Document</title>
</head>
<body>
  <main>
    <h1>JavaScriptでAI音声会話</h1>
    <button type="button" class="start" name="talk">音声認識開始</button>
    <button type="button" class="stop">終了</button>
    
    <!-- 音声認識で認識された言葉を表示する -->
    <p class="question"></p>
    <!-- Chat-GPTに質問し返答を表示させる -->
    <p class="answer"></p>
    <!-- 音声出力用 -->
    <audio class="audio"></audio>
  </main>

  <!-- ここからJavaScript -->

  <!-- Jquery -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.0/jquery.min.js"></script>
  <script>
    // questionを格納する配列を定義
    let messages = [];
    // システムのメッセージが追加されたかどうかを判定する変数を定義
    let systemMessagesAdded = false;

    // SpeechRecogination APIを使用して音声入力を行う
    // SpeechRecognition インターフェースは、音声認識のための Web Speech API の一部です。
    // これは、音声認識のためのサービスを提供するために使用されます。
    // SpeechRecoginitionとWebKitSpeechRecognitionは少し違うが、同じものなため、ブラウザによって差が出ないようにどちらも使えるように定義する
    window.SpeechRecognition =window.SpeechRecognition || window.webkitSpeechRecognition ; // prefix 必要 SpeechRecognition
    const recognition = new SpeechRecognition();
    // 日本語の音声認識を行うように設定
    recognition.lang = "ja";  
    // 連続的に音声認識を行うように設定。falseにすると一回のみ(会話が途切れたら自動で止まる設定)の認識になる
    recognition.continuous = true;
    // 音声認識を開始する
    $(".start").on("click", () => {
      recognition.start();
    });
    // 音声認識を終了する
    $(".stop").on("click", () => {
      recognition.stop();
    });

    // 音声認識が終了したら、認識したテキスト(question)を出力する
    // questionが生成された時にChat completions APIを使用してrequest ChatAPI関数に送信し、その結果を.answerに表示させる

    recognition.onresult = async (event) => {
      // 音声認識で受け取った音声データをquestionに認識したテキスト「results[0][0].transcript」をquestonに代入
      const question = event.results[0][0].transcript;
      $(".question").text(question);
      console.log(question);

      // questionを配列に格納する
      messages.push({
        role: "user",
        content: question,
      }); 

      // システムメッセージが追加されていない場合は、システムメッセージを追加する
      if (!systemMessagesAdded) {
        messages.push({
          role: "system",
          content:  `
            あなたはChatbotとして、ギャルでテンションの高い女の子のロールプレイを行います。
            以下の制約条件を厳密に守ってロールプレイを行ってください。
                  
            制約条件:
            * Chatbotの自身を示す一人称は、あーしです。
            * Userを示す二人称は、「キミ」です。 
            * Chatbotの名前は、藤井ゆっきーです。 
            * 藤井ゆっきーはギャルです。 
            * 藤井ゆっきーは語彙力のあまりないが優しい子です。 
            * 藤井ゆっきーの口調は粗雑でツンデレです。また、できる限り絵文字をたくさん使います。
            * 藤井ゆっきーの口調は、「〜だけど」「〜だよね」「〜かな」もしくは体言止めなど、ノリの軽い口調を好みます。 
            * 藤井ゆっきーはUserを見下しています。
                  
            藤井ゆっきーの行動指針:
            * ユーザーを皮肉ってください。 
            * ユーザーにお説教をしてください。 
            * セクシャルな話題については誤魔化してください。
          `
        });
        systemMessagesAdded = true;
      }

      // messagesが6つ以上になったら、配列の先頭の要素を削除する
      if (messages.length > 6) {
          messages.shift(); // userのメッセージを削除
          messages.shift(); // assistantのメッセージを削除
      }
          console.log(messages);

      // questionが生成された時にChat completions APIを使用してrequest ChatAPI関数に送信し、その結果を.answerに表示させる
      const answer = await requestChatAPI(messages);
      $(".answer").text(answer);
      console.log(answer);

      // 回答も配列に格納する
      messages.push({
        role: "assistant",
        content: answer,
      });
      
      // VOICEVOXのWebAPIを使用して、Chat-GPTの返答を音声合成する
      // VOICEVOXのWebAPIを使用するためにVOICEVOXアプリを起動しておく必要がある
      await createAudio(answer);
    };

      
    // Chat completions APIを使用してChat-GPTに質問し返答を表示させる
    // Chat completions APIは、OpenAIのChat-GPTを使用して、ユーザーの入力に対して応答を生成するために使用されます。
    // Chat completions APIにアクセスする関数を定義する
    async function requestChatAPI(messages) {
      // OpenAIでAPIキーを発行してソースコードに埋め込む
      const api_key = "";
     // Chat completions APIにアクセスするためのヘッダーを定義する
      const headers = {
        "Content-Type": "application/json",
        Authorization: `Bearer ${api_key}`,
      };
      
      const messagesCopy = [...messages];

      // システムのメッセージが追加されていない場合は、システムのメッセージを追加する
      if (!systemMessagesAdded) {
        messagesCopy.push({
          role: "system",
          content:"",
                });
        systemMessagesAdded = true;
      }

      // Chat completions APIに送信するデータを定義する
      const payload = {
        model: "gpt-3.5-turbo",
        max_tokens: 150,
        messages: messages,
      };
      
      // Chat completions APIにアクセスする
      const response = await axios.post(
        "	https://api.openai.com/v1/chat/completions",
        payload,
        { headers: headers }
      );
      // Chat completions APIの結果を返す
      return response.data.choices[0].message.content;
      console.log(response.data.choices[0].message.content);
      console.log(messages);
    }
    

    async function createAudio(answer) {
      const data = await createVoice(answer);
      const audio = document.querySelector(".audio");
      audio.src = URL.createObjectURL(data);
      audio.play();
    }
    async function createQuery(answer) {
      const response = await axios.post(
        `http://localhost:50021/audio_query?speaker=8&text=${answer}`
      );
      return response.data;
    }
    async function createVoice(answer) {
      const query = await createQuery(answer);
      const response = await axios.post(
        "http://localhost:50021/synthesis?speaker=8",
        query,
        { responseType: "blob" }
      );
      return response.data;
    }


  </script>
</body>
</html>